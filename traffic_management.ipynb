{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "your_reddit_username = \"<enter your username here>\"\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = f\"Scraper 1.0 by /u/{your_reddit_username}\"\n",
    "reddit = praw.Reddit (\n",
    "client_id=client_id,\n",
    "client_secret=client_secret,\n",
    "user_agent=user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from word_forms.word_forms import get_word_forms\n",
    "# \"public\", \"infrastructure\", \"planning\", \"urban\", \"civil\",\n",
    "keyword_list = {\"transport\", \"traffic\", \"travel\", \"transit\", \"experience\", \"commute\", \"urban\", \"civil\", \"accelerate\", \"rule\", \"etiquette\", \"confuse\", \"empathy\", \"application\", \n",
    "                \"device\", \"digital\", \"facility\", \"design\", \"captain\", \"jam\", \"booking\", \"crossing\", \"crowd\", \"walkway\", \"linkway\", \"signal\", \n",
    "                \"route\", \"path\", \"destination\", \"bridge\", \"flyover\", \"overhead\", \"barrier\", \"stuffy\", \"spacious\", \"service\", \"breakdown\", \"bunching\", \"replace\", \"uncomfortable\", \n",
    "                \"journey\", \"network\", \"challenge\", \"recommendation\", \"suggestion\", \"affordable\", \"connectivity\", \"available\", \"condition\", \"speed\", \"fast\", \"slow\", \"smooth\", \n",
    "                \"stress\", \"welfare\", \"frequency\", \"certainty\", \"uncertainty\", \"licence\", \"COE\", \"management\", \"rail\", \"double decker\", \"operator\", \"elevator\", \n",
    "                \"escalator\", \"equipment\", \"brake\", \"disruption\", \"accident\", \"incident\", \"fatality\", \"dangerous\", \"roadworks\", \"construction\", \"deploy\", \"manpower\", \"expansion\", \n",
    "                \"extension\", \"incentive\", \"child-friendly\", \"family\", \"stroller\", \"pram\", \"luggage\", \"baggage\", \"baby\", \"pregnant\", \"infant\", \"molest\", \"harassment\", \n",
    "                \"family-friendly\", \"signage\", \"announcement\", \"visibility\", \"communication\", \"display\", \"aware\", \"behaviour\", \"navigation\", \"advisory\", \"update\", \"risk\", \n",
    "                \"warning\", \"injury\", \"hazard\", \"assist\", \"guide\", \"concession\", \"sticker\", \"board\", \"toilet\", \"provision\", \"accommodate\", \"information\", \"real-time\", \"handicap\", \n",
    "                \"hurry\", \"emergency\", \"wheelchair\", \"user\", \"peak-hour\", \"difficulty\", \"infrastructure\", \"institution\", \"authority\", \"ministry\", \"shuttle\", \"SBS\", \n",
    "                \"station\", \"platform\", \"technology\", \"engineering\", \"upgrade\", \"concern\", \"need\", \"grievance\", \"pain point\", \"problem\", \"solution\", \"delay\", \"stop\", \n",
    "                \"rush\", \"wait\", \"queue\", \"interchange\", \"development\", \"road\", \"lane\", \"street\", \"highway\", \"expressway\", \"causeway\", \"boulevard\", \"avenue\", \"bus\", \"car\", \"train\", \n",
    "                \"taxi\", \"cab\", \"vehicle\", \"truck\", \"bike\", \"bicycle\", \"motor\", \"vehicle\", \"metro\", \"MRT\", \"mass rapid transit\", \"SMRT\", \"LRT\", \"light rail transit\", \"drive\", \n",
    "                \"walk\", \"ride\", \"cycle\", \"park\", \"arrival\", \"departure\", \"duration\", \"comfort\", \"quality\", \"efficiency\", \"convenience\", \"regularity\", \"reliability\", \"punctual\", \n",
    "                \"timely\", \"inclusivity\", \"accessibility\", \"disability\", \"EZ-Link\", \"TransitLink\", \"simplygo\", \"CEPAS\", \"ERP\", \"electronic road pricing\", \"maintain\", \"improve\", \n",
    "                \"seats\", \"safety\", \"LTA\", \"land transport authority\", \"ticket\", \"pedestrian\", \"passenger\", \"patron\", \"commuter\", \"intersection\", \"demand\", \"expectation\", \"system\", \n",
    "                \"innovation\", \"governance\", \"PTC\", \"public transport council\" \"congestion\", \"fare\", \"fuel\", \"petrol\", \"diesel\", \"gas\", \"mobility\", \"distance\", \"mode\", \"trip\"}\n",
    "for word in keyword_list.copy():\n",
    "    word_forms = get_word_forms(word, similarity_threshold=0.8)\n",
    "    for key in word_forms:\n",
    "        for form in word_forms[key]:\n",
    "            keyword_list.add(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list= ['\"' + s + '\"' for s in keyword_list]\n",
    "keyword_list = ', '.join(keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = reddit.subreddit(\"singapore+asksingapore+singaporehappenings+drivingsg\")\n",
    "\n",
    "# creating lists for storing scraped data\n",
    "ids=[]\n",
    "titles=[]\n",
    "content=[]\n",
    "comments=[]\n",
    "\n",
    "# looping over posts and scraping it\n",
    "chunk_size = 20\n",
    "iter = 0\n",
    "while iter <= len(keyword_list)-chunk_size+1: \n",
    "    for submission in subreddits.search(keyword_list[iter:iter+chunk_size], time_filter=\"all\"):\n",
    "        if submission.upvote_ratio > 0.7 and submission.score > 50 and submission.id not in ids: \n",
    "            ids.append(submission.id)\n",
    "            titles.append(submission.title)\n",
    "            content.append(submission.selftext[:min(len(submission.selftext), 2000)])\n",
    "            submission_comments = []\n",
    "            for comment in submission.comments:\n",
    "                if isinstance(comment, praw.models.MoreComments):\n",
    "                    continue\n",
    "                if comment.score > 10: \n",
    "                    submission_comments.append(comment.body[:min(len(comment.body), 2000)])\n",
    "            comments.append(submission_comments)\n",
    "\n",
    "    iter = iter + chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() \n",
    "df['id'] = ids\n",
    "df['title'] = titles\n",
    "df['content'] = content\n",
    "df['comment'] = comments\n",
    "\n",
    "df.to_csv('data/reddit_data.csv')\n",
    "df.to_json('data/reddit_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "genai.configure(api_key=<api_key>)\n",
    "\n",
    "prompt1 = \"\"\"Your task is to distill the essence of a given reddit post into a concise summary capturing the key points and essential information, \n",
    "within a 10-word limit.\\n\n",
    "If the post is not related to the subject of transportation, simply output 'unrelated' without any text formatting.\\n\n",
    "If, however, the post is about transportation, extract the following information.\\n\n",
    "Summary\\n\n",
    "Category 1 - The most appropriate category for the type of post from the following: complaint, suggestion, praise, query, information/news. Do not make up any categories of your own. If you are unsure of the category, put the category as 'other'.\\n \n",
    "Category 2 - The most appropriate category for the subject of the post from the following: bus service, train service, private transport, walk/cycle, policy/regulation, infrastructure/facilities/systems. Do not make up any categories of your own. If you are unsure of the category, put the category as 'other'.\\n\n",
    "Output the extracted  information in the following format: 'summary: <summary>\\ncategory 1: <category 1>\\ncategory 2: <category 2>'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-pro\", safety_settings=safety_settings)\n",
    "\n",
    "def generate_gemini_content(transcript_text, prompt, model):\n",
    "    response = model.generate_content(prompt + transcript_text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = list()\n",
    "categories_1 = list()\n",
    "categories_2 = list()\n",
    "#df = df.iloc[:10].copy(deep=True)\n",
    "for index, row in df.iterrows():\n",
    "    #print(index)\n",
    "    flag = False\n",
    "    if not len(row[\"content\"]) == 0:\n",
    "        try: \n",
    "            output = generate_gemini_content(row[\"content\"], prompt1, model)\n",
    "        except:\n",
    "            #print(f'error at {index}')\n",
    "            df = df.drop(index)   \n",
    "        else:\n",
    "            #print(index)\n",
    "            flag = True          \n",
    "    elif not len(row[\"title\"]) == 0:\n",
    "        try: \n",
    "            output = generate_gemini_content(row[\"title\"], prompt1, model)\n",
    "        except:\n",
    "            #print(f'error at {index}')\n",
    "            df = df.drop(index)\n",
    "        else:\n",
    "            #print(index)\n",
    "            flag = True\n",
    "    if flag:\n",
    "        if output.lower() == \"unrelated\":\n",
    "            df = df.drop(index)\n",
    "            continue\n",
    "        output = output.split('\\n')\n",
    "        output = [i for i in output if i != '']\n",
    "        print(f'{index}: {output}')\n",
    "        flag = 0\n",
    "        try:\n",
    "            flag = 1\n",
    "            summaries.append(output[0].split(':')[-1].strip())\n",
    "            flag = 2\n",
    "            categories_1.append(output[-2].split(':')[-1].strip())\n",
    "            flag = 3\n",
    "            categories_2.append(output[-1].split(':')[-1].strip()) \n",
    "        except:\n",
    "            message = \"couldn't generate\"\n",
    "            if flag == 1:\n",
    "                summaries.append(message)\n",
    "                categories_1.append(message)\n",
    "                categories_2.append(message)\n",
    "            if flag == 2:\n",
    "                categories_1.append(message)\n",
    "                categories_2.append(message)\n",
    "            if flag == 3:\n",
    "                categories_2.append(messgae)\n",
    "        #categories_3.append(output[-1].split(':')[-1].lstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"summary\"] = summaries\n",
    "df[\"category1\"] = categories_1\n",
    "df[\"category2\"] = categories_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_3 = list()\n",
    "\n",
    "cross_reference = {'bus service': ['frequency', 'punctuality', 'accessibility', 'affordability', 'quality', 'safety', 'connectivity', 'crowding', 'infrastructure/facilities'],\n",
    "                  'train service': ['frequency', 'punctuality', 'accessibility', 'affordability', 'quality', 'safety', 'connectivity', 'crowding', 'infrastructure/facilities'],\n",
    "                  'private transport': ['cost', 'parking', 'safety', 'traffic/congestion', 'connectivity'],\n",
    "                  'walk/cycle': ['safety', 'infrastructure/facilities'],\n",
    "                  'policy/regulation': ['enforcement', 'compliance', 'transparency/communication', 'impact'],\n",
    "                  'other': 'other'\n",
    "                  }\n",
    "\n",
    "prompt2 = f\"\"\"Your task is to categorise social media content about transportation in Singapore. The input will be provided to you in following format:'content: <content>\\ncategory: <category>'. \n",
    "You need to match the category to a key in the dictionary below and return the most suitable subcategory from the corresponding list in the following format: 'category: <category>'. \n",
    "Do not make up any new categories. If there is no key in the dictionary that matches the input return'other'.\\n{cross_reference}\"\"\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    category = row[\"category2\"]\n",
    "    content = row[\"summary\"]\n",
    "    input = f'content: {content}\\ncategory: {category}'\n",
    "    try:\n",
    "        output = generate_gemini_content(input, prompt2, model)\n",
    "    except:\n",
    "        categories_3.append(\"couldn't generate\")\n",
    "    else:\n",
    "        categories_3.append(output.split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category3\"] = categories_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/reddit_data_w_summary_categories.csv')\n",
    "df.to_json('data/reddit_data_w_summary_categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = df.select_dtypes('object')\n",
    "df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cross_reference:\n",
    "    print(df.loc[df['category2'] == cat][\"category3\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = df[\"category2\"].value_counts().keys()\n",
    "sizes = df[\"category2\"].value_counts()\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "94c92834a315c8ece64bc1f764f7bcf2a67c075ab6e072b5380520430a54dbb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
